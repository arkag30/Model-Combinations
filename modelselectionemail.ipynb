{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('spam1.csv')\n",
    "x= dataframe[\"text\"]\n",
    "y= dataframe[\"label\"]\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMmodel=Pipeline([('vectorizer',CountVectorizer()),('SVM',svm.SVC(C=100, gamma=0.001, kernel='rbf'))])\n",
    "NBmodel=Pipeline([('vectorizer',CountVectorizer()),('nb',MultinomialNB())])\n",
    "DTmodel=Pipeline([('vectorizer',CountVectorizer()),('DecisionTree',DecisionTreeClassifier())])\n",
    "RFmodel=Pipeline([('vectorizer',CountVectorizer()),('RandomTree',RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Arrays import *\n",
    "def confusion_matrix(actual, predicted):\n",
    "    arr=[[0,0],[0,0]]\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i] == 'ham':\n",
    "            arr[0][0]=arr[0][0]+1\n",
    "        elif actual[i] == predicted[i] == 'spam':\n",
    "            arr[1][1]=arr[1][1]+1\n",
    "        elif actual[i] != predicted[i] and predicted[i] == 'spam':\n",
    "            arr[1][0]=arr[1][0]+1\n",
    "        else:\n",
    "            arr[0][1]=arr[0][1]+1\n",
    "    accuracy=(arr[0][0]+arr[1][1])/(arr[0][0]+arr[0][1]+arr[1][0]+arr[1][1])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.970360824742268, 0.9742268041237113, 0.9735824742268041, 0.9677835051546392, 0.9658505154639175, 0.9677835051546392, 0.967139175257732, 0.9690721649484536, 0.9658505154639175, 0.9716494845360825]\n",
      "0.9693298969072165\n",
      "0.9742268041237113\n"
     ]
    }
   ],
   "source": [
    "#SVM only\n",
    "score=[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output=[SVMmodel.predict(input)]\n",
    "        if output[0] == ['spam']:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    score.append(accuracy)\n",
    "print(score)\n",
    "average_score=sum(score) / len(score)\n",
    "print(average_score)\n",
    "print(max(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9800257731958762, 0.9716494845360825, 0.9800257731958762, 0.9716494845360825, 0.9838917525773195, 0.9800257731958762, 0.9742268041237113, 0.9806701030927835, 0.9755154639175257, 0.9780927835051546]\n",
      "0.9775773195876288\n",
      "0.9838917525773195\n"
     ]
    }
   ],
   "source": [
    "#NB only\n",
    "score=[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output=[NBmodel.predict(input)]\n",
    "        if output[0] == ['spam']:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    score.append(accuracy)\n",
    "print(score)\n",
    "average_score=sum(score) / len(score)\n",
    "print(average_score)\n",
    "print(max(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9291237113402062, 0.9490979381443299, 0.9484536082474226, 0.9362113402061856, 0.9323453608247423, 0.9452319587628866, 0.9349226804123711, 0.9317010309278351, 0.9445876288659794, 0.9413659793814433]\n",
      "0.9393041237113401\n",
      "0.9490979381443299\n"
     ]
    }
   ],
   "source": [
    "#DT only\n",
    "score=[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output=[DTmodel.predict(input)]\n",
    "        if output[0] == ['spam']:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    score.append(accuracy)\n",
    "print(score)\n",
    "average_score=sum(score) / len(score)\n",
    "print(average_score)\n",
    "print(max(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9619845360824743, 0.967139175257732, 0.9652061855670103, 0.9780927835051546, 0.9677835051546392, 0.9690721649484536, 0.9664948453608248, 0.9755154639175257, 0.9722938144329897, 0.9845360824742269]\n",
      "0.9708118556701031\n",
      "0.9845360824742269\n"
     ]
    }
   ],
   "source": [
    "#RF only\n",
    "score=[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output=[RFmodel.predict(input)]\n",
    "        if output[0] == ['spam']:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    score.append(accuracy)\n",
    "print(score)\n",
    "average_score=sum(score) / len(score)\n",
    "print(average_score)\n",
    "print(max(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9710051546391752, 0.9722938144329897, 0.9735824742268041, 0.9742268041237113, 0.9755154639175257, 0.9819587628865979, 0.9735824742268041, 0.9716494845360825, 0.9826030927835051, 0.979381443298969]\n",
      "0.9755798969072165\n",
      "0.9826030927835051\n"
     ]
    }
   ],
   "source": [
    "#SVM and NB\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[SVMmodel.predict(input)]\n",
    "        output2=[NBmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score >= 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)\n",
    "print(max(ensembled_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9471649484536082, 0.9568298969072165, 0.9568298969072165, 0.9503865979381443, 0.9690721649484536, 0.9600515463917526, 0.9684278350515464, 0.9542525773195877, 0.9548969072164949, 0.9639175257731959]\n",
      "0.9581829896907216\n",
      "0.9690721649484536\n"
     ]
    }
   ],
   "source": [
    "#SVM and DT\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[SVMmodel.predict(input)]\n",
    "        output2=[DTmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score >= 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)\n",
    "print(max(ensembled_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9639175257731959, 0.9716494845360825, 0.9626288659793815, 0.961340206185567, 0.9632731958762887, 0.970360824742268, 0.9626288659793815, 0.961340206185567, 0.9626288659793815, 0.9664948453608248]\n",
      "0.9646262886597936\n",
      "0.9716494845360825\n"
     ]
    }
   ],
   "source": [
    "#SVM and RF\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[SVMmodel.predict(input)]\n",
    "        output2=[RFmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)\n",
    "print(max(ensembled_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9536082474226805, 0.9555412371134021, 0.961340206185567, 0.9664948453608248, 0.9606958762886598, 0.9529639175257731, 0.9471649484536082, 0.9606958762886598, 0.9664948453608248, 0.9600515463917526]\n",
      "0.9585051546391753\n",
      "0.9664948453608248\n"
     ]
    }
   ],
   "source": [
    "#NB and DT\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[DTmodel.predict(input)]\n",
    "        output2=[NBmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)\n",
    "print(max(ensembled_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9710051546391752, 0.9722938144329897, 0.9710051546391752, 0.9735824742268041, 0.9639175257731959, 0.976159793814433, 0.9658505154639175, 0.9697164948453608, 0.9652061855670103, 0.9729381443298969]\n",
      "0.9701675257731959\n",
      "0.976159793814433\n"
     ]
    }
   ],
   "source": [
    "#NB and RF\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[RFmodel.predict(input)]\n",
    "        output2=[NBmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)\n",
    "print(max(ensembled_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9465033838221076, 0.9619722848855946, 0.9300676764421527, 0.9394134708346761, 0.9390912020625202, 0.9390912020625202, 0.9374798582017403, 0.9494038027715115, 0.955526909442475, 0.9452143087334838]\n",
      "0.9443764099258782\n",
      "0.9619722848855946\n"
     ]
    }
   ],
   "source": [
    "#DT and RF\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.6,random_state = None)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[DTmodel.predict(input)]\n",
    "        output2=[RFmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)\n",
    "print(max(ensembled_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9832474226804123, 0.9819587628865979, 0.9806701030927835, 0.9851804123711341, 0.9838917525773195, 0.9845360824742269, 0.9838917525773195, 0.979381443298969, 0.9800257731958762, 0.9826030927835051]\n",
      "0.9825386597938144\n",
      "0.9851804123711341\n"
     ]
    }
   ],
   "source": [
    "#SVM NB and DT\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[SVMmodel.predict(input)]\n",
    "        output2=[NBmodel.predict(input)]\n",
    "        output3=[DTmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output3[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)\n",
    "print(max(ensembled_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9832474226804123, 0.9768041237113402, 0.9755154639175257, 0.9845360824742269, 0.9806701030927835, 0.9806701030927835, 0.9787371134020618, 0.9826030927835051, 0.9832474226804123, 0.9813144329896907]\n",
      "0.9807345360824742\n",
      "0.9845360824742269\n"
     ]
    }
   ],
   "source": [
    "#SVM NB and RF\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[SVMmodel.predict(input)]\n",
    "        output2=[NBmodel.predict(input)]\n",
    "        output3=[RFmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output3[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)\n",
    "print(max(ensembled_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9755154639175257, 0.9864690721649485, 0.9858247422680413, 0.9832474226804123, 0.9806701030927835, 0.9871134020618557, 0.9819587628865979, 0.9851804123711341, 0.9838917525773195, 0.9800257731958762]\n",
      "0.9829896907216495\n",
      "0.9871134020618557\n"
     ]
    }
   ],
   "source": [
    "#RF NB and DT\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[RFmodel.predict(input)]\n",
    "        output2=[NBmodel.predict(input)]\n",
    "        output3=[DTmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output3[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)\n",
    "print(max(ensembled_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9787371134020618, 0.9729381443298969, 0.9800257731958762, 0.9780927835051546, 0.9742268041237113, 0.9787371134020618, 0.9755154639175257, 0.9710051546391752, 0.9684278350515464, 0.9755154639175257]\n",
      "0.9753221649484536\n",
      "[0.9787371134020618, 0.9729381443298969, 0.9800257731958762, 0.9780927835051546, 0.9742268041237113, 0.9787371134020618, 0.9755154639175257, 0.9710051546391752, 0.9684278350515464, 0.9755154639175257]\n"
     ]
    }
   ],
   "source": [
    "#SVM DT and RF\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[RFmodel.predict(input)]\n",
    "        output2=[SVMmodel.predict(input)]\n",
    "        output3=[DTmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output3[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9838917525773195, 0.9864690721649485, 0.9813144329896907, 0.9871134020618557, 0.9877577319587629, 0.9884020618556701, 0.976159793814433, 0.9813144329896907, 0.9845360824742269, 0.9806701030927835]\n",
      "0.9837628865979381\n",
      "0.9884020618556701\n"
     ]
    }
   ],
   "source": [
    "#All 4\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[SVMmodel.predict(input)]\n",
    "        output2=[NBmodel.predict(input)]\n",
    "        output3=[DTmodel.predict(input)]\n",
    "        output4=[RFmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 0.3\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 0.3\n",
    "        if output3[0] == ['spam']:\n",
    "            spam_score = spam_score + 0.2\n",
    "        if output4[0] == ['spam']:\n",
    "            spam_score = spam_score + 0.2\n",
    "        if spam_score > 0.5:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)\n",
    "print(max(ensembled_score))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "100f4baee3945e2cd8f9ca899426d7aa87597db3eeb03ef4bb91bac7e04d77c6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
