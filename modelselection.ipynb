{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>EmailText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                          EmailText\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('spam.csv')\n",
    "x= dataframe[\"EmailText\"]\n",
    "y= dataframe[\"Label\"]\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMmodel=Pipeline([('vectorizer',CountVectorizer()),('SVM',svm.SVC(C=100, gamma=0.001, kernel='rbf'))])\n",
    "NBmodel=Pipeline([('vectorizer',CountVectorizer()),('nb',MultinomialNB())])\n",
    "DTmodel=Pipeline([('vectorizer',CountVectorizer()),('DecisionTree',DecisionTreeClassifier())])\n",
    "RFmodel=Pipeline([('vectorizer',CountVectorizer()),('RandomTree',RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Arrays import *\n",
    "def confusion_matrix(actual, predicted):\n",
    "    arr=[[0,0],[0,0]]\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i] == 'ham':\n",
    "            arr[0][0]=arr[0][0]+1\n",
    "        elif actual[i] == predicted[i] == 'spam':\n",
    "            arr[1][1]=arr[1][1]+1\n",
    "        elif actual[i] != predicted[i] and predicted[i] == 'spam':\n",
    "            arr[1][0]=arr[1][0]+1\n",
    "        else:\n",
    "            arr[0][1]=arr[0][1]+1\n",
    "    accuracy=(arr[0][0]+arr[1][1])/(arr[0][0]+arr[0][1]+arr[1][0]+arr[1][1])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.979066985645933, 0.9784688995215312, 0.9832535885167464, 0.9772727272727273, 0.986244019138756, 0.9796650717703349, 0.9856459330143541, 0.9826555023923444, 0.9880382775119617, 0.9850478468899522]\n",
      "0.9825358851674642\n"
     ]
    }
   ],
   "source": [
    "#SVM only\n",
    "score=[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output=[SVMmodel.predict(input)]\n",
    "        if output[0] == ['spam']:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    score.append(accuracy)\n",
    "print(score)\n",
    "average_score=sum(score) / len(score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9892344497607656, 0.9796650717703349, 0.9910287081339713, 0.9856459330143541, 0.9850478468899522, 0.9874401913875598, 0.986244019138756, 0.9904306220095693, 0.9838516746411483, 0.986244019138756]\n",
      "0.9864832535885165\n"
     ]
    }
   ],
   "source": [
    "#NB only\n",
    "score=[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output=[NBmodel.predict(input)]\n",
    "        if output[0] == ['spam']:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    score.append(accuracy)\n",
    "print(score)\n",
    "average_score=sum(score) / len(score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9671052631578947, 0.9706937799043063, 0.9659090909090909, 0.97188995215311, 0.972488038277512, 0.9683014354066986, 0.972488038277512, 0.9665071770334929, 0.97188995215311, 0.9742822966507177]\n",
      "0.9701555023923444\n"
     ]
    }
   ],
   "source": [
    "#DT only\n",
    "score=[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output=[DTmodel.predict(input)]\n",
    "        if output[0] == ['spam']:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    score.append(accuracy)\n",
    "print(score)\n",
    "average_score=sum(score) / len(score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9712918660287081, 0.9748803827751196, 0.972488038277512, 0.972488038277512, 0.9736842105263158, 0.9772727272727273, 0.9712918660287081, 0.9826555023923444, 0.9742822966507177, 0.9820574162679426]\n",
      "0.9752392344497606\n"
     ]
    }
   ],
   "source": [
    "#RF only\n",
    "score=[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output=[RFmodel.predict(input)]\n",
    "        if output[0] == ['spam']:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    score.append(accuracy)\n",
    "print(score)\n",
    "average_score=sum(score) / len(score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9892344497607656, 0.986244019138756, 0.9838516746411483, 0.9886363636363636, 0.9904306220095693, 0.9898325358851675, 0.9796650717703349, 0.9874401913875598, 0.9838516746411483, 0.9820574162679426]\n",
      "0.9861244019138755\n"
     ]
    }
   ],
   "source": [
    "#SVM and NB\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[SVMmodel.predict(input)]\n",
    "        output2=[NBmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score >= 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9748803827751196, 0.9784688995215312, 0.9748803827751196, 0.9748803827751196, 0.9796650717703349, 0.9772727272727273, 0.9700956937799043, 0.9748803827751196, 0.9730861244019139, 0.9754784688995215]\n",
      "0.9753588516746412\n"
     ]
    }
   ],
   "source": [
    "#SVM and DT\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[SVMmodel.predict(input)]\n",
    "        output2=[DTmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score >= 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9677033492822966, 0.9766746411483254, 0.9671052631578947, 0.9712918660287081, 0.9808612440191388, 0.9694976076555024, 0.9736842105263158, 0.9694976076555024, 0.972488038277512, 0.9826555023923444]\n",
      "0.973145933014354\n"
     ]
    }
   ],
   "source": [
    "#SVM and RF\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[SVMmodel.predict(input)]\n",
    "        output2=[RFmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9832535885167464, 0.9844497607655502, 0.9760765550239234, 0.9754784688995215, 0.9736842105263158, 0.972488038277512, 0.9688995215311005, 0.9754784688995215, 0.9778708133971292, 0.9814593301435407]\n",
      "0.9769138755980862\n"
     ]
    }
   ],
   "source": [
    "#NB and DT\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[DTmodel.predict(input)]\n",
    "        output2=[NBmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9712918660287081, 0.9748803827751196, 0.9766746411483254, 0.9694976076555024, 0.9760765550239234, 0.965311004784689, 0.9748803827751196, 0.97188995215311, 0.9748803827751196, 0.9748803827751196]\n",
      "0.9730263157894736\n"
     ]
    }
   ],
   "source": [
    "#NB and RF\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[RFmodel.predict(input)]\n",
    "        output2=[NBmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9569377990430622, 0.9680023923444976, 0.965011961722488, 0.965311004784689, 0.9641148325358851, 0.9635167464114832, 0.9605263157894737, 0.9605263157894737, 0.9629186602870813, 0.96561004784689]\n",
      "0.9632476076555024\n"
     ]
    }
   ],
   "source": [
    "#DT and RF\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.6,random_state = None)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[DTmodel.predict(input)]\n",
    "        output2=[RFmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.992822966507177, 0.986244019138756, 0.9856459330143541, 0.9868421052631579, 0.9856459330143541, 0.9856459330143541, 0.986244019138756, 0.9844497607655502, 0.9868421052631579, 0.9838516746411483]\n",
      "0.9864234449760764\n"
     ]
    }
   ],
   "source": [
    "#SVM NB and DT\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[SVMmodel.predict(input)]\n",
    "        output2=[NBmodel.predict(input)]\n",
    "        output3=[DTmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output3[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9856459330143541, 0.986244019138756, 0.979066985645933, 0.9856459330143541, 0.9850478468899522, 0.9880382775119617, 0.9844497607655502, 0.9826555023923444, 0.9844497607655502, 0.986244019138756]\n",
      "0.984748803827751\n"
     ]
    }
   ],
   "source": [
    "#SVM NB and RF\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[SVMmodel.predict(input)]\n",
    "        output2=[NBmodel.predict(input)]\n",
    "        output3=[RFmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output3[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9814593301435407, 0.9832535885167464, 0.9808612440191388, 0.9850478468899522, 0.9856459330143541, 0.9838516746411483, 0.9778708133971292, 0.9856459330143541, 0.9820574162679426, 0.9814593301435407]\n",
      "0.9827153110047846\n"
     ]
    }
   ],
   "source": [
    "#RF NB and DT\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[RFmodel.predict(input)]\n",
    "        output2=[NBmodel.predict(input)]\n",
    "        output3=[DTmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output3[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9832535885167464, 0.9820574162679426, 0.9814593301435407, 0.9850478468899522, 0.9754784688995215, 0.9808612440191388, 0.9838516746411483, 0.9850478468899522, 0.9754784688995215, 0.9796650717703349]\n",
      "0.9812200956937798\n"
     ]
    }
   ],
   "source": [
    "#SVM DT and RF\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[RFmodel.predict(input)]\n",
    "        output2=[SVMmodel.predict(input)]\n",
    "        output3=[DTmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if output3[0] == ['spam']:\n",
    "            spam_score = spam_score + 1\n",
    "        if spam_score > 1:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9844497607655502, 0.9814593301435407, 0.9796650717703349, 0.9784688995215312, 0.9868421052631579, 0.9844497607655502, 0.9832535885167464, 0.9838516746411483, 0.9826555023923444, 0.9838516746411483]\n",
      "0.9828947368421049\n"
     ]
    }
   ],
   "source": [
    "#All 4\n",
    "ensembled_score = []\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state = None)\n",
    "    SVMmodel.fit(x_train,y_train)\n",
    "    NBmodel.fit(x_train,y_train)\n",
    "    DTmodel.fit(x_train,y_train)\n",
    "    RFmodel.fit(x_train,y_train)\n",
    "    xlist=list(x_test)\n",
    "    ylist=list(y_test)\n",
    "    predicted = []\n",
    "    for j in xlist:\n",
    "        input=[j]\n",
    "        spam_score = 0\n",
    "        output1=[SVMmodel.predict(input)]\n",
    "        output2=[NBmodel.predict(input)]\n",
    "        output3=[DTmodel.predict(input)]\n",
    "        output4=[RFmodel.predict(input)]\n",
    "        if output1[0] == ['spam']:\n",
    "            spam_score = spam_score + 0.3\n",
    "        if output2[0] == ['spam']:\n",
    "            spam_score = spam_score + 0.3\n",
    "        if output3[0] == ['spam']:\n",
    "            spam_score = spam_score + 0.2\n",
    "        if output4[0] == ['spam']:\n",
    "            spam_score = spam_score + 0.2\n",
    "        if spam_score > 0.5:\n",
    "            predicted.append('spam')\n",
    "        else:\n",
    "            predicted.append('ham')\n",
    "    accuracy = confusion_matrix(ylist, predicted)\n",
    "    ensembled_score.append(accuracy)\n",
    "print(ensembled_score)\n",
    "average_score=sum(ensembled_score) / len(ensembled_score)\n",
    "print(average_score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "100f4baee3945e2cd8f9ca899426d7aa87597db3eeb03ef4bb91bac7e04d77c6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
